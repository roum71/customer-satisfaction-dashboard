#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Customer Satisfaction Dashboard â€” v10.7 (Fixed & Stable)
Unified | Secure | Multi-Center | Lookup | KPI Gauges | Dimensions | Pareto | Services Overview
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import io, re
from datetime import datetime
from pathlib import Path

# =========================================================
# ğŸ” USERS
# =========================================================
import streamlit as st

USER_KEYS = {
    "Public Services Department": {
        "password": st.secrets["users"]["Public_Services_Department"],
        "role": "center",
        "file": "Center_Public_Services.csv"
    },
    "Ras Al Khaimah Municipality": {
        "password": st.secrets["users"]["Ras_Al_Khaimah_Municipality"],
        "role": "center",
        "file": "Center_RAK_Municipality.csv"
    },
    "Sheikh Saud Center-Ras Al Khaimah Courts": {
        "password": st.secrets["users"]["Sheikh_Saud_Center"],
        "role": "center",
        "file": "Center_Sheikh_Saud_Courts.csv"
    },
    "Sheikh Saqr Center-Ras Al Khaimah Courts": {
        "password": st.secrets["users"]["Sheikh_Saqr_Center"],
        "role": "center",
        "file": "Center_Sheikh_Saqr_Courts.csv"
    },
    "Executive Council": {
        "password": st.secrets["users"]["Executive_Council"],
        "role": "admin",
        "file": "Centers_Master.csv"
    }
}


# =========================================================
# PAGE CONFIG
# =========================================================
st.set_page_config(page_title="Ù„ÙˆØ­Ø© ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…ØªØ¹Ø§Ù…Ù„ÙŠÙ† â€” Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©", layout="wide")
PASTEL = px.colors.qualitative.Pastel

# =========================================================
# LANGUAGE
# =========================================================
lang = st.sidebar.radio("ğŸŒ Ø§Ù„Ù„ØºØ© / Language", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"], index=0)
if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
    st.markdown("""
        <style>
        html, body, [class*="css"] {direction:rtl;text-align:right;font-family:"Tajawal","Cairo","Segoe UI";}
        </style>
    """, unsafe_allow_html=True)

# =========================================================
# LOGIN
# =========================================================
params = st.query_params
center_from_link = params.get("center", [None])[0]
center_options = list(USER_KEYS.keys())

if center_from_link and center_from_link in USER_KEYS:
    selected_center = center_from_link
else:
    st.sidebar.header("ğŸ¢ Ø§Ø®ØªØ± Ø§Ù„Ù…Ø±ÙƒØ² / Select Center")
    selected_center = st.sidebar.selectbox("Select Center / Ø§Ø®ØªØ± Ø§Ù„Ù…Ø±ÙƒØ²", center_options)

if "authorized" not in st.session_state:
    st.session_state.update({"authorized": False, "center": None, "role": None})

if not st.session_state["authorized"] or st.session_state["center"] != selected_center:
    st.sidebar.subheader("ğŸ”‘ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± / Password")
    password = st.sidebar.text_input("Password", type="password")
    if password == USER_KEYS[selected_center]["password"]:
        st.session_state.update({
            "authorized": True,
            "center": selected_center,
            "role": USER_KEYS[selected_center]["role"],
            "file": USER_KEYS[selected_center]["file"]
        })
        st.success(f"âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙƒÙ…Ø±ÙƒØ²: {selected_center}")
        st.rerun()
    elif password:
        st.error("ğŸš« ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©.")
        st.stop()
    else:
        st.warning("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±.")
        st.stop()

center, role = st.session_state["center"], st.session_state["role"]

# =========================================================
# LOAD DATA
# =========================================================
def safe_read(file):
    try:
        return pd.read_csv(file, encoding="utf-8", low_memory=False)
    except Exception:
        return None

file_path = USER_KEYS[center]["file"]
df = safe_read(file_path)
if df is None:
    st.error(f"âŒ ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {file_path}")
    st.stop()

# =========================================================
# LOOKUP TABLES
# =========================================================
lookup_path = Path("Data_tables.xlsx")
lookup_catalog = {}
if lookup_path.exists():
    xls = pd.ExcelFile(lookup_path)
    for sheet in xls.sheet_names:
        tbl = pd.read_excel(xls, sheet_name=sheet)
        tbl.columns = [c.strip().upper() for c in tbl.columns]
        lookup_catalog[sheet.upper()] = tbl

# =========================================================
# UTILS
# =========================================================
def series_to_percent(vals):
    vals = pd.to_numeric(vals, errors="coerce").dropna()
    if len(vals) == 0:
        return np.nan
    mx = vals.max()
    if mx <= 5: return ((vals - 1)/4*100).mean()
    elif mx <= 10: return ((vals - 1)/9*100).mean()
    else: return vals.mean()

def detect_nps(df):
    cands = [c for c in df.columns if "nps" in c.lower() or "recommend" in c.lower()]
    if not cands: return np.nan, 0, 0, 0
    s = pd.to_numeric(df[cands[0]], errors="coerce").dropna()
    if len(s)==0: return np.nan, 0, 0, 0
    promoters = (s>=9).sum()
    passives = ((s>=7)&(s<=8)).sum()
    detractors = (s<=6).sum()
    total = len(s)
    promoters_pct = promoters/total*100
    passives_pct = passives/total*100
    detractors_pct = detractors/total*100
    nps = promoters_pct - detractors_pct
    return nps, promoters_pct, passives_pct, detractors_pct
# =========================================================
# FILTERS
# =========================================================
filter_cols = [c for c in df.columns if any(k in c.upper() for k in ["GENDER", "SERVICE", "SECTOR", "NATIONALITY", "CENTER"])]
filters = {}

df_filtered = df.copy()

with st.sidebar.expander("ğŸ›ï¸ Ø§Ù„ÙÙ„Ø§ØªØ± / Filters"):
    for col in filter_cols:
        lookup_name = col.strip().upper()
        mapped = False
        if lookup_name in lookup_catalog:
            tbl = lookup_catalog[lookup_name]
            tbl.columns = [c.strip().upper() for c in tbl.columns]
            
            # Detect columns (case-insensitive)
            ar_col = next((c for c in tbl.columns if "ARABIC" in c or "SERVICE2" in c), None)
            en_col = next((c for c in tbl.columns if "ENGLISH" in c), None)
            code_col = next((c for c in tbl.columns if "CODE" in c or lookup_name in c), None)

            if code_col and ((lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" and ar_col) or (lang == "English" and en_col)):
                name_col = ar_col if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else en_col
                name_map = dict(zip(tbl[code_col].astype(str), tbl[name_col].astype(str)))
                df_filtered[col] = df_filtered[col].astype(str).map(name_map).fillna(df_filtered[col])
                mapped = True
        
        if not mapped:
            st.sidebar.warning(f"âš ï¸ Lookup not applied for {col}")

        options = df_filtered[col].dropna().unique().tolist()
        selection = st.multiselect(col, options, default=options)
        filters[col] = selection

for col, values in filters.items():
    df_filtered = df_filtered[df_filtered[col].isin(values)]

df = df_filtered.copy()


# =========================================================
# ğŸ“ˆ TABS
# =========================================================
tab_data, tab_sample, tab_kpis, tab_dimensions, tab_services, tab_pareto = st.tabs(
    ["ğŸ“ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø©", "ğŸ“Š Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª", "ğŸ§© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯", "ğŸ“‹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª", "ğŸ’¬ Pareto"]
)


# =========================================================
# ğŸ“ DATA TAB â€” Multi-language headers
# =========================================================
with tab_data:
    st.subheader("ğŸ“ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ÙÙ„Ø§ØªØ±")

    questions_map_ar, questions_map_en = {}, {}
    if "QUESTIONS" in lookup_catalog:
        qtbl = lookup_catalog["QUESTIONS"]
        qtbl.columns = [c.strip().upper() for c in qtbl.columns]
        code_col = next((c for c in qtbl.columns if "CODE" in c or "DIMENSION" in c), None)
        ar_col = next((c for c in qtbl.columns if "ARABIC" in c or c == "ARABIC"), None)
        en_col = next((c for c in qtbl.columns if "ENGLISH" in c or c == "ENGLISH"), None)

        if code_col and ar_col and en_col:
            qtbl["CODE_NORM"] = qtbl[code_col].astype(str).str.strip().str.upper()
            questions_map_ar = dict(zip(qtbl["CODE_NORM"], qtbl[ar_col]))
            questions_map_en = dict(zip(qtbl["CODE_NORM"], qtbl[en_col]))

    df_display = df.copy()
    df_display.columns = [c.strip() for c in df_display.columns]
    ar_row = [questions_map_ar.get(c.strip().upper(), "") for c in df_display.columns]
    en_row = [questions_map_en.get(c.strip().upper(), "") for c in df_display.columns]
    df_final = pd.concat([pd.DataFrame([ar_row, en_row], columns=df_display.columns), df_display], ignore_index=True)

    st.dataframe(df_final, use_container_width=True)
    ts = datetime.now().strftime("%Y-%m-%d_%H%M")
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        df_final.to_excel(writer, index=False)
    st.download_button("ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", buffer.getvalue(), file_name=f"Filtered_Data_{ts}.xlsx")




# =========================================================
# ğŸ“ˆ SAMPLE TAB
# =========================================================
# =========================================================
# ğŸ“ˆ SAMPLE TAB  â€” Ø¥ØµØ¯Ø§Ø± Ø­Ø¯ÙŠØ« ÙˆÙ…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª
# =========================================================
with tab_sample:
    st.subheader("ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø© (Ø¥ØµØ¯Ø§Ø± Ø­Ø¯ÙŠØ«)")
    st.warning("ğŸ”„ Sample Tab - New Version Loaded")

    total = len(df)
    st.markdown(f"### ğŸ§® Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯: {total:,}")

    # ğŸŸ© Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
    chart_type = st.radio(
        "ğŸ“Š Ù†ÙˆØ¹ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ",
        ["Pie Chart", "Bar Chart", "Clustered Bar", "Stacked Bar", "Grid / Matrix"],
        index=1,
        horizontal=True
    )

    # ğŸŸ¨ Ø§Ø®ØªÙŠØ§Ø± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¹Ø±Ø¶
    value_type = st.radio(
        "ğŸ“ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¹Ø±Ø¶",
        ["Numbers (Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯)", "Percentages (Ø§Ù„Ù†Ø³Ø¨ Ø§Ù„Ù…Ø¦ÙˆÙŠØ©)"],
        index=1,
        horizontal=True
    )

    # ğŸŸ¦ Ø§Ø®ØªÙŠØ§Ø± Ù…ØªØºÙŠØ± Ø¥Ø¶Ø§ÙÙŠ ÙÙŠ Ø­Ø§Ù„Ø© Clustered Ø£Ùˆ Stacked Bar
    extra_dim = None
    if chart_type in ["Clustered Bar", "Stacked Bar"]:
        possible_cols = [c for c in df.columns if c not in ["CENTER"] and df[c].nunique() < 15]
        extra_dim = st.selectbox("ğŸ“š Ø§Ø®ØªØ± Ù…ØªØºÙŠØ± Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„ØªØ¬Ù…ÙŠØ¹", ["None"] + possible_cols)
        if extra_dim == "None":
            extra_dim = None

    # ğŸŸª ØªÙ†ÙÙŠØ° Ø§Ù„Ø±Ø³Ù… Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©
    for col in filter_cols:
        counts = df[col].value_counts().reset_index()
        counts.columns = [col, "Count"]
        counts["Percentage"] = counts["Count"] / total * 100
        value_col = "Count" if value_type.startswith("Numbers") else "Percentage"
        title = f"{col} â€” {total:,} Ø±Ø¯"

        # ğŸ“Š Pie Chart
        if chart_type == "Pie Chart":
            fig = px.pie(
                counts, names=col, values=value_col,
                hole=0.3, title=title, color_discrete_sequence=PASTEL
            )

        # ğŸ“Š Bar Chart
        elif chart_type == "Bar Chart":
            fig = px.bar(
                counts, x=col, y=value_col, text=value_col,
                color=col, color_discrete_sequence=PASTEL, title=title
            )
            fig.update_traces(
                texttemplate="%{text:.1f}" if value_type.startswith("Percent") else "%{text}",
                textposition="outside"
            )

        # ğŸ“Š Clustered Bar
        elif chart_type == "Clustered Bar" and extra_dim and extra_dim in df.columns:
            grouped = df.groupby([col, extra_dim]).size().reset_index(name="Count")
            grouped["Percentage"] = grouped["Count"] / grouped["Count"].sum() * 100
            fig = px.bar(
                grouped, x=col, y=value_col, color=extra_dim,
                barmode="group", text=value_col, title=f"{col} Ø­Ø³Ø¨ {extra_dim}",
                color_discrete_sequence=PASTEL
            )
            fig.update_traces(
                texttemplate="%{text:.1f}" if value_type.startswith("Percent") else "%{text}",
                textposition="outside"
            )

        # ğŸ“Š Stacked Bar
        elif chart_type == "Stacked Bar" and extra_dim and extra_dim in df.columns:
            grouped = df.groupby([col, extra_dim]).size().reset_index(name="Count")
            grouped["Percentage"] = grouped["Count"] / grouped["Count"].sum() * 100
            fig = px.bar(
                grouped, x=col, y=value_col, color=extra_dim,
                barmode="stack", text=value_col,
                title=f"{col} (Stacked by {extra_dim})",
                color_discrete_sequence=PASTEL
            )
            fig.update_traces(
                texttemplate="%{text:.1f}" if value_type.startswith("Percent") else "%{text}",
                textposition="inside"
            )

        # ğŸ§© Grid / Matrix View
        elif chart_type == "Grid / Matrix":
            st.write(f"### ğŸ§© Ø¹Ø±Ø¶ Ø´Ø¨ÙƒÙŠ â€” {col}")
            matrix = counts[[col, "Count", "Percentage"]].copy()
            matrix.columns = ["Ø§Ù„Ù‚ÙŠÙ…Ø©", "Ø§Ù„Ø¹Ø¯Ø¯", "Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ©"]
            st.dataframe(matrix.style.format({"Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ©": "{:.1f}%"}), use_container_width=True)
            continue  # Ù„Ø§ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù‡Ù†Ø§

        # ğŸ“ˆ Ø¹Ø±Ø¶ Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        if chart_type != "Grid / Matrix":
            st.plotly_chart(fig, use_container_width=True)


# =========================================================
# ğŸ“Š KPIs TAB â€” 3 gauges + NPS breakdown
# =========================================================
with tab_kpis:
    st.subheader("ğŸ“Š Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (CSAT / CES / NPS)")
    csat = series_to_percent(df.get("Dim6.1", pd.Series(dtype=float)))
    ces = series_to_percent(df.get("Dim6.2", pd.Series(dtype=float)))
    nps, prom, passv, detr = detect_nps(df)

    c1, c2, c3 = st.columns(3)
    for col, val, name in zip([c1, c2, c3], [csat, ces, nps], ["CSAT", "CES", "NPS"]):
        fig = go.Figure(go.Indicator(
            mode="gauge+number",
            value=val if not np.isnan(val) else 0,
            title={'text': name},
            gauge={'axis': {'range': [0, 100]},
                   'steps': [{'range': [0, 60], 'color': '#f5b7b1'},
                             {'range': [60, 80], 'color': '#fcf3cf'},
                             {'range': [80, 100], 'color': '#c8f7c5'}],
                   'bar': {'color': '#2ecc71'}}))
        col.plotly_chart(fig, use_container_width=True)

    st.markdown(f"""
    #### ğŸ” ØªÙØ§ØµÙŠÙ„ Ù…Ø¤Ø´Ø± NPS
    - **Promoters (Ø§Ù„Ù…Ø±ÙˆØ¬ÙˆÙ†):** {prom:.1f}%
    - **Passives (Ø§Ù„Ù…Ø­Ø§ÙŠØ¯ÙˆÙ†):** {passv:.1f}%
    - **Detractors (Ø§Ù„Ù…Ø¹Ø§Ø±Ø¶ÙˆÙ†):** {detr:.1f}%
    """)

# =========================================================
# ğŸ§© DIMENSIONS TAB
# =========================================================

# =========================================================
# ğŸ§© DIMENSIONS TAB
# =========================================================
with tab_dimensions:
    st.subheader("ğŸ§© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯")

    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ© Ù…Ø«Ù„ Dim1.1, Dim2.3, ...
    all_dim_cols = [c for c in df.columns if re.match(r"Dim\d+\.", c.strip())]

    if not all_dim_cols:
        st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© ÙØ±Ø¹ÙŠØ© Ù„Ù„Ø£Ø¨Ø¹Ø§Ø¯ (Ù…Ø«Ù„ Dim1.1, Dim2.3 ...).")
    else:
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· Ù„ÙƒÙ„ Ø¨Ø¹Ø¯ Ø±Ø¦ÙŠØ³ÙŠ (Dim1 Ø¥Ù„Ù‰ Dim5)
        main_dims = {}
        for i in range(1, 6):  # ÙŠØ´Ù…Ù„ Dim1 Ø­ØªÙ‰ Dim5
            sub_cols = [c for c in df.columns if c.startswith(f"Dim{i}.")]
            if sub_cols:
                main_dims[f"Dim{i}"] = df[sub_cols].mean(axis=1)

        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¥Ù„Ù‰ DataFrame
        for k, v in main_dims.items():
            df[k] = v

        # Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ù„Ø®Øµ Ø§Ù„Ù‚ÙŠÙ…
        summary = []
        for dim in [f"Dim{i}" for i in range(1, 6)]:
            if dim in df.columns:
                avg = series_to_percent(df[dim])
                summary.append({"Dimension": dim, "Score": avg})
        dims = pd.DataFrame(summary).dropna()

        # Ø±Ø¨Ø· Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù…Ù† Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
        if "QUESTIONS" in lookup_catalog:
            qtbl = lookup_catalog["QUESTIONS"]
            qtbl.columns = [c.strip().upper() for c in qtbl.columns]
            code_col = next((c for c in qtbl.columns if "CODE" in c or "DIMENSION" in c), None)
            ar_col = next((c for c in qtbl.columns if "ARABIC" in c), None)
            en_col = next((c for c in qtbl.columns if "ENGLISH" in c), None)
            if code_col and ar_col and en_col:
                qtbl["CODE_NORM"] = qtbl[code_col].astype(str).str.strip()
                name_map = dict(zip(qtbl["CODE_NORM"],
                                    qtbl[ar_col if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else en_col]))
                dims["Dimension_name"] = dims["Dimension"].map(name_map)

        # Ø±Ø³Ù… Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        fig = px.bar(
            dims.sort_values("Score", ascending=False),
            x="Dimension_name" if "Dimension_name" in dims.columns else "Dimension",
            y="Score", text="Score",
            color_discrete_sequence=PASTEL,
            title="ØªØ­Ù„ÙŠÙ„ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯"
        )
        fig.update_traces(texttemplate="%{text:.1f}%", textposition="outside")
        fig.update_layout(yaxis_title="Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ© (%)")

        st.plotly_chart(fig, use_container_width=True)
        st.dataframe(dims, use_container_width=True)

# =========================================================
# ğŸ“‹ SERVICES TAB
# =========================================================
with tab_services:
    st.subheader("ğŸ“‹ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª")
    if "SERVICE" not in df.columns:
        st.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ Ù„Ù„Ø®Ø¯Ù…Ø§Øª.")
    else:
        svc_summary = df.groupby("SERVICE").agg({"Dim6.1":"mean","Dim6.2":"mean"}).reset_index()
        svc_summary.rename(columns={"Dim6.1":"CSAT","Dim6.2":"CES"}, inplace=True)
        st.dataframe(svc_summary, use_container_width=True)
        fig = px.bar(svc_summary, x="SERVICE", y=["CSAT","CES"], barmode="group", color_discrete_sequence=PASTEL)
        st.plotly_chart(fig, use_container_width=True)

# =========================================================
# ğŸ’¬ PARETO TAB
# =========================================================
with tab_pareto:
    st.subheader("ğŸ’¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª (Pareto)")
    text_cols = [c for c in df.columns if any(k in c.lower() for k in ["comment","Ù…Ù„Ø§Ø­Ø¸","unsat","reason"])]
    if not text_cols:
        st.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ Ù†ØµÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Pareto.")
    else:
        col = text_cols[0]
        df["__clean"] = df[col].astype(str).str.lower()
        df["__clean"] = df["__clean"].replace(r"[^\u0600-\u06FFA-Za-z0-9\s]", " ", regex=True)
        df["__clean"] = df["__clean"].replace(r"\s+", " ", regex=True).str.strip()
        empty_terms = {""," ","Ù„Ø§ ÙŠÙˆØ¬Ø¯","Ù„Ø§ÙŠÙˆØ¬Ø¯","Ù„Ø§ Ø´ÙŠØ¡","no","none","nothing","Ø¬ÙŠØ¯","Ù…Ù…ØªØ§Ø²","ok"}
        df = df[~df["__clean"].isin(empty_terms)]
        df = df[df["__clean"].apply(lambda x: len(x.split()) >= 3)]

        themes = {
            "Parking / Ù…ÙˆØ§Ù‚Ù Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª":["Ù…ÙˆÙ‚Ù","Ù…ÙˆØ§Ù‚Ù","parking"],
            "Waiting / Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±":["Ø§Ù†ØªØ¸Ø§Ø±","Ø¨Ø·Ø¡","delay","slow"],
            "Staff / Ø§Ù„Ù…ÙˆØ¸ÙÙˆÙ†":["Ù…ÙˆØ¸Ù","ØªØ¹Ø§Ù…Ù„","staff"],
            "Fees / Ø§Ù„Ø±Ø³ÙˆÙ…":["Ø±Ø³ÙˆÙ…","Ø¯ÙØ¹","fee"],
            "Process / Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª":["Ø§Ø¬Ø±Ø§Ø¡","process","Ø§Ù†Ø¬Ø§Ø²"],
            "Platform / Ø§Ù„Ù…Ù†ØµØ©":["ØªØ·Ø¨ÙŠÙ‚","app","system"],
            "Facility / Ø§Ù„Ù…ÙƒØ§Ù†":["Ù…ÙƒØ§Ù†","Ù†Ø¸Ø§ÙØ©","Ø§Ø²Ø¯Ø­Ø§Ù…"],
            "Communication / Ø§Ù„ØªÙˆØ§ØµÙ„":["Ø±Ø¯","ØªÙˆØ§ØµÙ„","Ø§ØªØµØ§Ù„"]
        }

        def classify_theme(t):
            for th, ws in themes.items():
                if any(w in t for w in ws):
                    return th
            return "Other / Ø£Ø®Ø±Ù‰"

        df["Theme"] = df["__clean"].apply(classify_theme)
        df = df[df["Theme"] != "Other / Ø£Ø®Ø±Ù‰"]

        counts = df["Theme"].value_counts().reset_index()
        counts.columns = ["Theme","Count"]
        counts["%"] = counts["Count"]/counts["Count"].sum()*100
        counts["Cum%"] = counts["%"].cumsum()
        counts["Color"] = np.where(counts["Cum%"] <= 80,"#e74c3c","#95a5a6")

        all_answers = df.groupby("Theme")["__clean"].apply(lambda x:" / ".join(x.astype(str))).reset_index()
        counts = counts.merge(all_answers,on="Theme",how="left")
        counts.rename(columns={"__clean":"Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª"},inplace=True)

        st.dataframe(counts[["Theme","Count","%","Cum%","Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª"]]
                     .style.format({"%":"{:.1f}","Cum%":"{:.1f}"}), use_container_width=True)

        fig = go.Figure()
        fig.add_bar(x=counts["Theme"], y=counts["Count"], marker_color=counts["Color"], name="Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª")
        fig.add_scatter(x=counts["Theme"], y=counts["Cum%"], name="Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ©", yaxis="y2", mode="lines+markers")
        fig.update_layout(title="Pareto â€” Ø§Ù„Ù…Ø­Ø§ÙˆØ± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
                          yaxis=dict(title="Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"),
                          yaxis2=dict(title="Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)", overlaying="y", side="right"),
                          bargap=0.25, height=600)
        st.plotly_chart(fig, use_container_width=True)

        pareto_buffer = io.BytesIO()
        with pd.ExcelWriter(pareto_buffer, engine="openpyxl") as writer:
            counts.to_excel(writer, index=False, sheet_name="Pareto_Results")
        st.download_button("ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ Pareto (Excel)",
                           data=pareto_buffer.getvalue(),
                           file_name=f"Pareto_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")












